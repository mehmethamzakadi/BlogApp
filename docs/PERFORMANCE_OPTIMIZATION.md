# Performans OptimizasyonlarÄ±

Bu dokÃ¼manda BlogApp projesine uygulanan performans optimizasyonlarÄ± ve Ã¶lÃ§Ã¼m yÃ¶ntemleri aÃ§Ä±klanmaktadÄ±r.

## âœ… Uygulanan Optimizasyonlar

### 1. Database Connection Pool
**DeÄŸiÅŸiklik:** `appsettings.json` ve `appsettings.Development.json`

```
Pooling=true
Minimum Pool Size=10
Maximum Pool Size=200
Connection Idle Lifetime=300
Connection Pruning Interval=10
```

**KazanÃ§:** %40-60 daha hÄ±zlÄ± DB baÄŸlantÄ±sÄ±, connection overhead azalmasÄ±

### 2. EF Core Query Tracking
**DeÄŸiÅŸiklik:** `PersistenceServicesRegistration.cs` ve `EfRepositoryBase.cs`

- VarsayÄ±lan tracking: `NoTrackingWithIdentityResolution`
- Repository metodlarÄ±: `enableTracking = false` (varsayÄ±lan)
- Batch operations: `MaxBatchSize = 100`
- Retry logic: 3 deneme, 5 saniye max delay

**KazanÃ§:** %30-50 daha hÄ±zlÄ± read operasyonlarÄ±, %20 daha az memory kullanÄ±mÄ±

**Not:** Update/Delete iÅŸlemlerinde `enableTracking: true` kullanÄ±n:
```csharp
var post = await _postRepository.GetAsync(
    p => p.Id == id, 
    enableTracking: true
);
```

### 3. Redis Connection Pool
**DeÄŸiÅŸiklik:** `InfrastructureServicesRegistration.cs`

```
abortConnect=false
connectTimeout=5000
syncTimeout=5000
connectRetry=3
keepAlive=60
```

**KazanÃ§:** Daha stabil cache baÄŸlantÄ±sÄ±, timeout azalmasÄ±

### 4. Response Compression
**DeÄŸiÅŸiklik:** `Program.cs`

- Brotli + Gzip compression
- HTTPS Ã¼zerinde aktif
- Compression Level: Fastest

**KazanÃ§:** %60-80 daha kÃ¼Ã§Ã¼k response boyutu, bandwidth tasarrufu

### 5. Response Caching
**DeÄŸiÅŸiklik:** `Program.cs`

Middleware eklendi, controller'larda kullanÄ±m:
```csharp
[ResponseCache(Duration = 60, VaryByQueryKeys = new[] { "page" })]
public async Task<IActionResult> GetPosts() { }
```

**KazanÃ§:** Tekrarlayan isteklerde %90+ hÄ±z artÄ±ÅŸÄ±

### 6. Kestrel Server Limits
**DeÄŸiÅŸiklik:** `Program.cs`

```
MaxConcurrentConnections = 1000
MaxRequestBodySize = 10MB
KeepAliveTimeout = 2 dakika
```

**KazanÃ§:** Daha fazla eÅŸzamanlÄ± baÄŸlantÄ± desteÄŸi

---

## ğŸ“Š Performans Ã–lÃ§Ã¼m YÃ¶ntemleri

### 1. k6 Load Testing

**Kurulum:**
```bash
# Windows (Chocolatey)
choco install k6

# macOS
brew install k6

# Linux
sudo gpg -k
sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
sudo apt-get update
sudo apt-get install k6
```

**KullanÄ±m:**
```bash
# Projeyi baÅŸlat
cd src/BlogApp.API
dotnet run

# BaÅŸka bir terminal'de test Ã§alÄ±ÅŸtÄ±r
cd ../..
k6 run performance-test.js
```

**Ã‡Ä±ktÄ±:**
- Toplam istek sayÄ±sÄ±
- BaÅŸarÄ±sÄ±z istek oranÄ±
- Ortalama/P95/P99 response time
- Requests/second (throughput)

### 2. Apache Bench (Basit Test)

```bash
# 1000 istek, 50 eÅŸzamanlÄ± kullanÄ±cÄ±
ab -n 1000 -c 50 http://localhost:6060/api/post

# JSON POST isteÄŸi
ab -n 100 -c 10 -p post.json -T application/json http://localhost:6060/api/auth/login
```

### 3. Seq Log Analizi

**Seq'e eriÅŸim:** http://localhost:5341

**YavaÅŸ istekler:**
```
Elapsed > 1000
```

**Hata oranÄ±:**
```
StatusCode >= 500 | count() by StatusCode
```

**Ortalama response time (1 dakikalÄ±k):**
```
select avg(Elapsed) from stream group by time(1m)
```

### 4. PostgreSQL Query Monitoring

```sql
-- YavaÅŸ sorgular (pg_stat_statements extension gerekli)
SELECT 
    query, 
    mean_exec_time, 
    calls,
    total_exec_time
FROM pg_stat_statements 
ORDER BY mean_exec_time DESC 
LIMIT 10;

-- Aktif baÄŸlantÄ±lar
SELECT 
    count(*) as active_connections,
    state
FROM pg_stat_activity 
GROUP BY state;

-- Connection pool kullanÄ±mÄ±
SELECT 
    max_conn,
    used,
    res_for_super,
    max_conn - used - res_for_super as available
FROM (
    SELECT 
        setting::int AS max_conn,
        (SELECT count(*) FROM pg_stat_activity) AS used,
        (SELECT setting::int FROM pg_settings WHERE name = 'superuser_reserved_connections') AS res_for_super
    FROM pg_settings 
    WHERE name = 'max_connections'
) s;
```

---

## ğŸ¯ Beklenen Performans Metrikleri

### Optimizasyon Ã–ncesi
- **EÅŸzamanlÄ± KullanÄ±cÄ±:** 50-200
- **Avg Response Time:** 200-500ms
- **P95 Response Time:** 1000ms
- **Throughput:** ~100 req/s
- **DB Connection Pool:** 0-100 (dinamik)

### Optimizasyon SonrasÄ±
- **EÅŸzamanlÄ± KullanÄ±cÄ±:** 500-2000
- **Avg Response Time:** 50-150ms
- **P95 Response Time:** 300ms
- **Throughput:** 500-1000 req/s
- **DB Connection Pool:** 10-200 (optimize edilmiÅŸ)

**Not:** GerÃ§ek performans sunucu kaynaklarÄ±na (CPU, RAM, Disk I/O) baÄŸlÄ±dÄ±r.

---

## ğŸ”§ Ä°leri Seviye Optimizasyonlar (Opsiyonel)

### 1. PostgreSQL Tuning

Docker container'a girmek iÃ§in:
```bash
docker exec -it postgresdb bash
```

`postgresql.conf` dÃ¼zenlemeleri:
```conf
max_connections = 200
shared_buffers = 256MB
effective_cache_size = 1GB
maintenance_work_mem = 64MB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 1.1
effective_io_concurrency = 200
work_mem = 4MB
```

### 2. Docker Resource Limits

`docker-compose.yml` veya `docker-compose.prod.yml`:
```yaml
services:
  blogapp.api:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 512M
  
  postgresdb:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
```

### 3. Index Optimizasyonu

SÄ±k kullanÄ±lan sorgular iÃ§in index ekleyin:
```sql
-- Posts tablosu iÃ§in
CREATE INDEX idx_posts_categoryid ON "Posts"("CategoryId") WHERE "DeletedDate" IS NULL;
CREATE INDEX idx_posts_userid ON "Posts"("UserId") WHERE "DeletedDate" IS NULL;
CREATE INDEX idx_posts_createdat ON "Posts"("CreatedDate" DESC) WHERE "DeletedDate" IS NULL;

-- Comments tablosu iÃ§in
CREATE INDEX idx_comments_postid ON "Comments"("PostId") WHERE "DeletedDate" IS NULL;
```

### 4. Output Caching (Controller Seviyesi)

SÄ±k eriÅŸilen endpoint'lere cache ekleyin:
```csharp
[HttpGet]
[ResponseCache(Duration = 300, VaryByQueryKeys = new[] { "page", "pageSize" })]
public async Task<IActionResult> GetPosts([FromQuery] int page = 1)
{
    // ...
}
```

---

## ğŸ“ˆ Monitoring Dashboard (Opsiyonel)

### Grafana + Prometheus Entegrasyonu

1. **Prometheus Metrics Ekle:**
```bash
dotnet add package prometheus-net.AspNetCore
```

2. **Program.cs:**
```csharp
using Prometheus;

app.UseHttpMetrics();
app.MapMetrics();
```

3. **docker-compose.yml'e ekle:**
```yaml
prometheus:
  image: prom/prometheus
  volumes:
    - ./prometheus.yml:/etc/prometheus/prometheus.yml
  ports:
    - "9090:9090"

grafana:
  image: grafana/grafana
  ports:
    - "3000:3000"
```

---

## ğŸš¨ Dikkat Edilmesi Gerekenler

1. **enableTracking = false:** Update/Delete iÅŸlemlerinde `true` yapÄ±n
2. **Response Caching:** KullanÄ±cÄ±ya Ã¶zel data'da kullanmayÄ±n
3. **Connection Pool:** Ã‡ok yÃ¼ksek deÄŸerler PostgreSQL'i zorlayabilir
4. **Compression:** Zaten sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ dosyalarda (image, video) overhead yaratÄ±r
5. **Rate Limiting:** Mevcut ayarlar korundu, gerekirse artÄ±rÄ±n

---

## ğŸ“ Destek

Performans sorunlarÄ± iÃ§in:
1. Seq loglarÄ±nÄ± kontrol edin
2. PostgreSQL query stats'Ä± inceleyin
3. k6 test sonuÃ§larÄ±nÄ± analiz edin
4. Docker container resource kullanÄ±mÄ±nÄ± izleyin
